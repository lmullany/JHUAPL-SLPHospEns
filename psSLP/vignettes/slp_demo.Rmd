---
title: "Pre-Smoothed Simulated Linear Pooling"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Pre-Smoothed Simulated Linear Pooling}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width=7, 
  fig.height=4)
options(width = 120)

```

## Background

This is a statistical/mathematical approach to combining forecasts from component models, where the underlying distribution of forecasts from each model is unavailable, but rather, is only sparsely represented by a set of discrete points on the underlying quantile function. This is not substantially different from a standard problem whereby one desires access to underlying data but only has access to a smaller set of information from which the underlying data might, under certain conditions, be simulated.

The small number of functions in this package were designed specifically for the problem of combining forecasts from say, multiple models, where the underlying set of original data are not available. Specifically, imagine that we have $N$ models $i,1,2,\dots,N$, and for each, only a summary of the underlying forecasts is available in the form of a finite set of estimates from the quantile function (i.e. for each model $i$, $Q_{i}(p)=V$, where $V$ is the number of forecasted outcomes for which $p$ proportion of the $i^{th}$ model estimates fall).

------------------------------------------------------------------------

### [Simulated Linear Pooling]{.ul}

In this package, a continuous $\hat{Q_{i}(p)}$ is estimated by applying a generalized additive model with penalized cubic splines to the set of $(p,V)$ pairs. Uniform distribution variates are then drawn (in large number) and applied to this curve, to produce a simulated set of forecasts. The simulated forecasts from each component are summed together (i.e. linearly) to produce a single (multi-modal) simulated distribution. This simulated combined distribution of forecasts can be used to provide an "ensemble" estimate of the component models.

------------------------------------------------------------------------

### [Simple Approach / Vincentization]{.ul}

Obviously, a more simple and common approach to combining quantile functions in this situation is to simply take the mean of the values V over the component models, commonly known as *vincentization* (<https://en.wikipedia.org/wiki/Vincent_average>). Specifically for $N$ models $i=1,2,\dots,N$, each with a finite set of estimates from its corresponding quantile function $Q_{i}(p)$, the combined quantile function at any point p is $$Q_{ens}(p) = \frac{1}{N}\sum_{i=1}^{N}Q_{i}(p) $$

Optionally, weights could be added and/or the median of the component model estimates could be used.

------------------------------------------------------------------------

### [Pre-Smoothing to Reduce Volatility in Longitudinal Forecasts]{.ul}

For either algorithm, we address the situation where each component model is producing a longitudinal series of such forecasts (for example, on D days $d=1,2,\dots,D$). In some cases (i.e. depending on the estimation problem of interest), the volatility across time at a specific probability level, $p$, within a model might be considered a nuisance or noise factor to be reduced/removed, rather than a true effort at estimating such volatility. To address this specific need, we provide an optional and additional pre-processing step, prior to combining model estimates. This includes using locally-weighted regression smoothing to reduce volatility in the $Q_{i}(p)$ levels across different time points for a particular component model. This smoothed version of $Q_{i}(p)_{sm}$ is then used in the above approach rather than original non-smoothed $Q_{i}(p)$ from each component.

------------------------------------------------------------------------

## Demonstration of Simulated Linear Pooling

This vignette provides a very basic example of using the package to:

1.  Simulate a set of forecasts from a single set of pairs $(p,V)$

2.  Simulate a combined quantile function from multiple quantile functions using:

    -   Simulated Linear Pooling

    -   Simple Vincentization

3.  Pre-Smooth a set of forecasts from a single model

```{r setup, include=FALSE, echo=FALSE}
# Load necessary libraries for this demonstration
library(psSLP)
library(data.table)
library(ggplot2)
```

### [Simulate a set of forecasts from a single set of pairs, $(p,V)$]{.ul}

First, we will generate a single hypothetical forecast with 23 quantile levels

```{r generate_data}
# Set a sequence of probability levels, p
forecast_1 = data.table::data.table(
  p = c(0.01,0.025,seq(0.05,0.95,0.05),0.975,0.99),
  qp = c(0,1,3,4,6,8,9,10,11,15,17,19,20,25,27,30,31,31,53,82,85,104,164)
)
forecast_1 %>% head()
```

Next, we plot these data

```{r plot_forecast1, echo=FALSE}
plt <- ggplot(data=forecast_1,aes(p,qp)) + 
  geom_point(color="red",size=2) + 
  geom_line(size=1.5) + 
  labs(x="p", y="Q(p)") + 
  ggtitle("Quantile function estimates - Forecast 1")
plt
```

A smooth curve using the `mgcv::gam()` can be added

```{r add_gam_curve, echo=FALSE}
plt <- plt + geom_smooth(method="gam",se=F, color='blue', size=1.5)
suppressMessages(print(plt))
```

The function `generate_slp_predictions()` simulates the underlying distribution from these raw data. See `??generate_slp_predictions` for more information, but the main parameters are as as below:

-   `x`: input dataframe

-   `qp_var`: name of the column holding the $Q(p)$ values

-   `p_var`: name of the column holding the $p$ values

-   `draw_size`: integer (default 1000) number of simulated values from the underlying distribution

-   `parallel`: one of "auto","on", or "off"; default is "auto", will run in parallel on half the available cores, if \>1000 gam models

-   `threads` = NULL, set an integer value of threads

We'll start by calling this function with the default parameters, along with specifying `x`, `qp_var`, and `p_var`

```{r}

# Simulate a 1000 observations from the underlying distribution
simulated_1 = generate_slp_predictions(
  x = forecast_1,
  qp_var = "qp",
  p_var = "p",
  gam_model_configuration = list(family="poisson"))

# plot a histogram of these
ggplot(simulated_1,aes(x=predictions,stat="identity")) + 
  geom_histogram(bins=100,fill="darkgreen") +
  labs(x="Predictions", y="Count") + 
  ggtitle("Simulated distribution from a single quantile function")

```

Let's compare the quantiles from this simulated distribution with the true (i.e. available) quantiles

```{r}
# add simulate quantiles
forecast_1[, sim_qp:= quantile(simulated_1$predictions, probs = p)]
```

```{r echo=FALSE}
# plot these
ggplot(
  data = melt(forecast_1,
              id.vars = "p",
              measure.vars = c("qp", "sim_qp"),
              value.name = "qp",
              variable.name = "qp_type")[,qp_type:=fifelse(qp_type=="qp", "Original Quantiles", "Estimated from Simulated Distribution")],
  aes(x=p,y=qp,color=qp_type)) + 
  geom_point(size=2)+
  geom_line(size=1.5)+
  labs(x="p", y = "Q(p)", color="Q(p) Type") + 
  theme(legend.position="bottom") + 
  ggtitle("Comparison of estimated and original quantiles from single forecast")

```

Obviously, the simulated quantile looks very similar to the original generalized additive model prediction curve, since the simulated data were derived from this approach when calling `generate_slp_predictions()`

------------------------------------------------------------------------

### [Simulate a combined quantile function from multiple quantile functions]{.ul}

The functionality in this package is best illustrated however in the situation where we have multiple model forecasts, and we want to combine them into a single ensemble forecast. In this next section, we demonstrate how this can be done, using the included example dataset `multiple_models.rda`

```{r}
# Load the data
data("multiple_models")
```

The data contains three columns: `quantile`, `outcomes`,`model`. The first two are simple the $(p,V)$ pairs referred to above, while the third distinguished the set of forecasts. Let's look at the first 6 rows:

```{r}
# Show first 6 rows
multiple_models %>% head()
```

We can plot these data, and see how different the quantile functions appear:

```{r, echo=F}
plt <- ggplot(multiple_models, aes(quantile,outcomes, color=model)) + 
  geom_point() + 
  geom_line() + 
  labs(x="p", y="Q(p)", color="Model") + 
  theme(legend.position="bottom") +
  ggtitle("Multiple quantile functions")

plt
```

Our task is to combine these individual forecasts. Obviously, the most simple and usually most appropriate is to simply take a (weighted) mean/median of the quantile-by-quantile submissions. This can be implemented simply using `generate_vinc_ensemble()`

```{r}
ens_vinc <- generate_vinc_ensemble(x=multiple_models,qp_var = "outcomes",p_var = "quantile",pooltype = "mean")

# view the ensemble
ens_vinc %>% head()


```

Let's overlay the simple $\hat{Q(p)}$ estimated here with the originals

```{r, echo=F}
plt <- plt + 
  geom_point(data = ens_vinc, aes(x=quantile, y=outcomes, color="Ensemble"), color="black", size=2) + 
  geom_line(data=ens_vinc, aes(x=quantile, y=outcomes, color="Ensemble"), color="black",size=2) + 
  ggtitle("Multiple quantile functions with simple Q-by-Q mean ensemble (black)")

plt

```

We can simulate the underlying distribution of each model, using `generate_slp_predictions()`, as we did above, but now taking advantage of the `byvars` option. Notice how model 2 has very little variability; the resulting simulated distribution for that model will be centered around a very small interval, relative to the other models

```{r}

# Generate the distributions
sim_distributions <- generate_slp_predictions(
  x = multiple_models,
  qp_var="outcomes",
  p_var="quantile",
  gam_model_configuration = list(family="poisson"), 
  byvar="model"
)

# Now, lets look at the result
sim_distributions[,.N,by=model]
```

We can plot these simulate distributions, as before:

```{r, echo=F}
ggplot(sim_distributions, aes(predictions, stat="identity", color=model,fill=model)) + 
  geom_histogram(bins=100)+ 
  facet_wrap(~model, scales="free_y",nrow=2) + 
  theme(legend.position="none") + 
  labs(x="Predictions", y="Count") + 
  ggtitle("Simulated Distributions")
  

```

If we simulate a distribution from the vincentization-combined quantile function, and compare to the joint distribution produced by linearly pooling the above 8 separately simulated simulations, we see that the latter is multi-modal, and has broader interval width

```{r, echo=F}

vinc_sim_dist <- generate_slp_predictions(ens_vinc,qp_var="outcomes",p_var = "quantile")

ggplot(rbind(vinc_sim_dist[,`:=`(model="vinc",type="Vincentization")], sim_distributions[,type:="SLP Ensemble"]),
       aes(predictions, stat="identity", color=type, fill=type)) +
  geom_density(size=2,alpha=0.3) + 
  theme(legend.position='bottom') +
  labs(x="Predictions", y="Density", color="",fill="") + 
  ggtitle("Joint distribution and distribution simulated from vincentization Q(p)")
  
```

We can use the `gen_slp_ensemble()` function immediately following the `gen_slp_predictions()` call to create the $\hat{Q_{slp}(p)}$ and compare to the one estimated through simple averaging of the quantile levels across models (i.e. $\hat{Q_{vinc}(p)}$ )

```{r}
# This line simply estimate the quantiles from the joint (multi-modal) distribution
slp_ensemble <- generate_slp_ensemble(sim_distributions,qp_var="predictions")

```

```{r, echo=F}
gginput <- rbind(slp_ensemble[, type:="SLP Ensemble"],ens_vinc[,type:="Vincentization"], use.names=FALSE)
ggplot(gginput, aes(quantile, predictions, color=type)) + 
  geom_point(size=2) + 
  geom_line(size=1.5) + 
  labs(x="p", y='Q(p)', color="") + 
  ggtitle("Comparison of Q(p) estimates by ensemble approach") + 
  theme(legend.position="bottom")

```

Notice how the ensemble approach will tend to produce a more disperse distribution.

------------------------------------------------------------------------

### [Pre-Smooth a set of forecasts from a single model]{.ul}

In some situations, we may have a model or set of models that are generating quantile functions longitudinally (i.e. over some time unit). In this situation, we may be interested in generated an ensemble forecast (i.e. $\hat{Q_{ens}(p)}$ ) for each unit of time. Further, we may want to smooth out day to day volatility in the indivudal model-level quantile functions. In this next section, we demonstrate how this can be done, using the included example dataset `multiple_models_over_time.rda`

```{r}
# Load the data
data("multiple_models_over_time")
```

This data set has the same structure as before, except now for each of the models, we have multiple quantile functions, one for each value of the new fourth column `val`. Let's assume this value is an indicator of time (it could be considered days, going from 1 to 28, i.e. 4 weeks).

First, lets look at the raw data for four models, over time:

```{r}

target_models = c("model 1", "model 5", "model 7", "model 8")
target_quantiles = c(0.01, 0.25, 0.5, 0.75, 0.99)

plt <- ggplot(
  data = multiple_models_over_time[
    model %in% target_models
    & quantile %in% target_quantiles], aes(val, outcomes, color=factor(quantile))) + 
  geom_point() + 
  geom_line() + 
  facet_wrap(~model, scales="free_y") + 
  theme(legend.position="bottom") + 
  labs(x="Time-Unit", y="Q(p)", color = "p") + 
  ggtitle("Quantile values over time, by model")
plt
```

We can use the `pre_smooth_quantile_functions()` function to take set of quantiles and pre-smooth them using locally weighted regression. Here, we set the `byvars` parameter to the separate models. There is an optional parameter, `loess_span` that can help control the level of smoothing; the default is 0.75 (see `??loess` for more information)

```{r}

ps_data <- pre_smooth_quantile_functions(
  x=multiple_models_over_time,
  qp_var="outcomes",
  p_var = "quantile",
  time_var="val",
  byvars="model")

```

The new dataset returned by this function contains the `qp_var`, the `time_var`, the `p_var`, and `byvars` (in this case, model), and a new variable containing the smoothed estiame of the quantile function. This new variable is by default named with a `_hat` suffixed to the name of the `qp_var`, but this can be changed by providing a string name in the optional `smooth_col_name` parameter.

```{r}
ps_data %>% head()
```

Now, lets' look at the same four models, now smoothed

```{r, echo=FALSE}

target_models = c("model 1", "model 5", "model 7", "model 8")
target_quantiles = c(0.01, 0.25, 0.5, 0.75, 0.99)

plt <- ggplot(
  data = ps_data[model %in% target_models & quantile %in% target_quantiles],
  aes(val, outcomes_hat, color=factor(quantile))) +
  
  geom_point() + 
  geom_line() + 
  facet_wrap(~model, scales="free_y") + 
  theme(legend.position="bottom") + 
  labs(x="Time-Unit", y="Q(p)", color = "p") + 
  ggtitle("Pre-Smoothed quantile values over time, by model")

plt
```

These pre-smoothed quantile functions can then of course be combined using either the vincentization or the simulated linear pooling method, as shown below.

```{r}
# Get simulate linear pooling of the pre-smoothed quantile functions (by model and time value)
ps_slp <- generate_slp_ensemble(
  generate_slp_predictions(
    x = ps_data, 
    qp_var="outcomes_hat",
    p_var = "quantile",
    byvars = c("model","val")
  ),
  byvars = "val"
)

```

We now have a an estimate of the combined quantile function across models, for each of the time_points. We can plot these over time, with desired prediction intervals. To do this, we manipulate the dataset to swing it wide, so that `geom_ribbon()` from the `ggplot2` package can be used to show these intervals

```{r}

ps_slp_wide <- dcast(
  data = ps_slp[as.character(quantile) %in% c("0.025","0.25","0.5","0.75","0.975")],
  formula = val~quantile,
  value.var = "predictions"
)

ps_slp_wide %>% head()

```

We then plot the ensemble over time

```{r, echo=FALSE}
plt <- ggplot(ps_slp_wide, aes(val,`0.5`)) + 
  geom_point() + 
  geom_line() + 
  geom_ribbon(aes(ymin=`0.025`, ymax=`0.975`), alpha=.3) +
  geom_ribbon(aes(ymin=`0.25`, ymax=`0.75`), alpha=.5) + 
  labs(x="Time-unit (val)", y="Q(p)") + 
  ggtitle("Pre-smoothed Simulated Linear Pooling Ensemble")
  
plt
```

Notice the difference between the ensemble pre-smoothed above, and if we had not pre-smoothed:

```{r, echo=FALSE, include=FALSE}
# Get simulate linear pooling of the raw quantile functions (by model and time value)
slp <- generate_slp_ensemble(
  generate_slp_predictions(
    x = multiple_models_over_time,
    qp_var="outcomes",
    p_var = "quantile",
    byvars = c("model","val")
  ),
  byvars = "val"
)
```

```{r, echo=FALSE}
slp_wide <- dcast(
  data = slp[as.character(quantile) %in% c("0.025","0.25","0.5","0.75","0.975")],
  formula = val~quantile,
  value.var = "predictions"
)

plt <- ggplot(slp_wide, aes(val,`0.5`)) + 
  geom_point() + 
  geom_line() + 
  geom_ribbon(aes(ymin=`0.025`, ymax=`0.975`), alpha=.3) +
  geom_ribbon(aes(ymin=`0.25`, ymax=`0.75`), alpha=.5) + 
  labs(x="Time-unit (val)", y="Q(p)") + 
  ggtitle("Simulated Linear Pooling Ensemble (No Smoothing)")
  
plt


```
